{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing structural manipulations with semantic pointers\n",
    "\n",
    "The purpose of this notebook is to illustrate how Nengo DL can be used to optimize the parameters of a Nengo model so as to more effectively support the retrieval of information from highly structured [semantic pointers](https://www.nengo.ai/build-a-brain/index.html). A related and simpler [example notebook](https://github.com/nengo/nengo_examples/blob/nengo_dl/deeplearning/CircularConvolution-Optimized-SoftLIFRate.ipynb) illustrates using Nengo DL to learn circular convolution, which is the basic binding operation used within Nengo to create semantic pointers with internal structure (i.e., pointers that arrange symbol-like representations into things such as lists and trees). Here, we will provide semantic pointers comprised of numerous bound items as inputs to a simple network, and then optimize the network's paramters such that when a particular cue is presented, the item associated with this cue in a particular pointer is produced as the network's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nengo\n",
    "import nengo.spa as spa\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate random semantic pointers\n",
    "\n",
    "The first thing to do is define a function that produces random examples of structured semantic pointers, cues, and the outputs that correspond to these cues. Below, a generation function is defined with parameters that determine how many examples are produced (`n_items`), how many bound pairs each example contain (`n_pairs`), and the vector dimensionality (`dims`). By default, the returned cues and outputs are from the first binding in each example. (Note that since the generated bindings are all random, it doesn't really matter which one is picked for creating the target cue-output pairing in this simple case. But if the cues have a specific interpretation, randomization can help insure that many different cues are included in the generated data) Each example consists of a collection of role-filler pairs of the following form: \n",
    "\n",
    "$SP_{TRACE} = Role_A \\circledast Filler_A + Role_B \\circledast Filler_B + Role_C \\circledast Filler_C$ \n",
    "\n",
    "where terms like $Role_A$ refer to simpler semantic pointers (i.e., distributed representations), the $\\circledast$ symbol denotes circular convolution, and the $SP_{TRACE}$ subscript highlights that the resulting pointer is a compressed or lossy encoding, in accordance with research on the nature of [holographic reduced representations](https://pdfs.semanticscholar.org/6456/98cdb52b0f1fdcac55da91e56f7ffd935d15.pdf).\n",
    "\n",
    "So, for a given cue (e.g., $Role_B$, the correct output or item to retrieve would be the corresponding filler (i.e., $Filler_B$). The model we'll build will perform such retrieval by performing a computation of the following sort:\n",
    "\n",
    "$SP_{TRACE} \\:\\: \\circledast \\sim Role_A \\approx Filler_A$\n",
    "\n",
    "Then, with the Nengo DL simulator, we'll optimize the model's parameters to help ensure that this computation is performed with high degree of accuracy (i.e., such that the presented cue always produces the correct model output). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(n_items, n_pairs, dims, seed, randomize_cues=False):\n",
    "\n",
    "    state = np.random.RandomState(seed)\n",
    "    vocab = spa.Vocabulary(dimensions=dims, rng=state, max_similarity=1)\n",
    "    \n",
    "    # create keys for identifying roles and fillers in each example\n",
    "    roles = ['ROLE_' + char for char in string.ascii_uppercase[:n_pairs]]\n",
    "    fills = ['FILL_' + char for char in string.ascii_uppercase[:n_pairs]]\n",
    "    \n",
    "    # initialize arrays of shape (n_inputs, n_steps, dims)\n",
    "    traces = np.zeros((n_items, 1, dims))\n",
    "    cues = np.zeros((n_items, 1, dims))\n",
    "    targets = np.zeros((n_items, 1, dims))\n",
    "    \n",
    "    # iterate through all of the examples to be generated\n",
    "    for n in range(n_items):\n",
    "        n_roles = [role + str(n) for role in roles]\n",
    "        n_fills = [fill + str(n) for fill in fills]\n",
    "        \n",
    "        pairs = zip(n_roles, n_fills)\n",
    "        pair_keys = []\n",
    "        \n",
    "        # create a binding key for each pair and add bound items to vocab\n",
    "        for x, y in pairs:\n",
    "            pair_keys.append(x + '*' + y)\n",
    "            vocab.add(x, vocab.create_pointer())\n",
    "            vocab.add(y, vocab.create_pointer())\n",
    "\n",
    "        # create key for the 'trace' of bound pairs (i.e. a structured SP)\n",
    "        trace_key = 'TRACE_' + str(n)\n",
    "        trace_ptr = vocab.parse('+'.join(pair_keys))\n",
    "        trace_ptr.normalize()\n",
    "        vocab.add(trace_key, trace_ptr) \n",
    "        \n",
    "        # pick which bound pair to use role for cue and filler for output\n",
    "        val = n_pairs - 1 if n_pairs >= 2 else 1\n",
    "        idx = np.random.randint(0, val, 1)[0] if randomize_cues else 0\n",
    "        \n",
    "        # fill array elements correspond to this example\n",
    "        traces[n, 0, :] = vocab[trace_key].v\n",
    "        cues[n, 0, :] = vocab[n_roles[idx]].v\n",
    "        targets[n, 0, :] = vocab[n_fills[idx]].v\n",
    "\n",
    "    return traces, cues, targets, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the model\n",
    "\n",
    "Next, we'll define a Nengo model that retrieves items from structured semantic pointers that are provided as input. We'll also produce some data for testing retrieval accuracy. Note that in this notebook, we won't use the Nengo [SPA library](https://github.com/nengo/nengo_spa) for defining model compenents, since it is useful to first understand what is going on strictly in terms of basic ensembles and connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 98\n",
    "dims = 32\n",
    "\n",
    "n_inputs = 20\n",
    "n_pairs = 2\n",
    "\n",
    "pointers, cues, targets, vocab = get_data(n_inputs, n_pairs, dims, seed=seed)\n",
    "\n",
    "with nengo.Network(seed=seed) as net:\n",
    "    # use rectified linear neurons to ensure differentiability\n",
    "    net.config[nengo.Ensemble].neuron_type = nengo.RectifiedLinear()\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "    \n",
    "    # provide a pointer and a cue as input to the network\n",
    "    ptr_inp = nengo.Node(vocab['TRACE_0'].v)\n",
    "    cue_inp = nengo.Node(vocab['ROLE_A0'].v)\n",
    "    \n",
    "    # create a convolution network to use the cue to retrieve some item\n",
    "    cconv = nengo.networks.CircularConvolution(5, dims, invert_b=True)\n",
    "    \n",
    "    # connect the trace and cue inputs to the circular convolution network\n",
    "    nengo.Connection(ptr_inp, cconv.input_a)\n",
    "    nengo.Connection(cue_inp, cconv.input_b)\n",
    "\n",
    "    # probe the output\n",
    "    out = nengo.Probe(cconv.output)\n",
    "    out_filtered = nengo.Probe(cconv.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test baseline retrieval accuracy\n",
    "\n",
    "Because the decoded outputs of the network are vectors, we'll first define a simple function that can be used to evaluate whether these decoded outputs are nearest to the vectors corresponding to each target output (i.e., the semantic pointer for the filler associated with the particular role provided as an input cue).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(sim, probe, vocab, targets, t_step=-1):\n",
    "    # provide a simulator instance, the probe being evaluated, the vocab,\n",
    "    # the target vocab keys, and the time step at which to evaluate\n",
    "\n",
    "    # determine batch_size and create (batch_size, dims) array of outputs\n",
    "    bsize = sim.data[probe].shape[0]\n",
    "    output = sim.data[probe][:, t_step, :]\n",
    "    output = np.reshape(output, (bsize, vocab.dimensions))\n",
    "\n",
    "    # compute similarity between each output and vocab item, then get key\n",
    "    # for the vocab item with highest similarity to each output\n",
    "    sims = np.dot(vocab.vectors, output.T)\n",
    "    idxs = np.argmax(sims, axis=0)\n",
    "    predicted = [vocab.keys[idxs[i]] for i in range(len(idxs))]\n",
    "\n",
    "    # compare the targets to predicted, return percent accuracy\n",
    "    pairs = list(zip(targets, predicted))\n",
    "    ratio = sum([x == y for x, y in pairs]) / len(pairs)\n",
    "\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the model on some test data to see what the baseline retrieval accuracy is. Since we used only a small number of neurons for each product computation in the circular convolution network, we should expect mediocre results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of target keys for the outputs produced by each input cue\n",
    "target_keys = ['FILL_A' + str(n) for n in range(n_inputs)]\n",
    "\n",
    "# create input and output data feeds for running the Nengo DL simulator \n",
    "test_inputs = {ptr_inp: pointers, cue_inp: cues}\n",
    "test_outputs = {out: targets}\n",
    "\n",
    "with nengo_dl.Simulator(net, minibatch_size=n_inputs, seed=seed) as sim:\n",
    "    # run the simulator for one time step to compute the network outputs \n",
    "    sim.step(input_feeds=test_inputs)\n",
    "\n",
    "print('Retrieval accuracy: ', accuracy(sim, out, vocab, target_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indicate that the model is only performing accurate retrieval ten percent of the time, which means that this network is not very capable of manipulating structured semantic pointers in a useful way. \n",
    "\n",
    "We can also run the simulator with the default inputs specified in the model definition to create a plot for visualizing the retrieval procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(net, seed=seed) as sim:\n",
    "    sim.run(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "output_vocab = vocab.create_subset([\"FILL_A%d\" % i for i in range(10)]) \n",
    "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[out_filtered], output_vocab))\n",
    "plt.legend(output_vocab.keys, loc=4)\n",
    "plt.ylim([-1, 1])\n",
    "plt.xlabel(\"t [s]\")\n",
    "plt.ylabel(\"Similarity\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in the model definition above, we provided `ROLE_A0` as the default input cue, in which case the correct output is `FILL_A0`. The actual output, by comparison, is not particularly similary to this desired output, which illustrates that the model is not performing accurate retrieval. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimize the model parameters\n",
    "\n",
    "Now, we'll train the network parameters to optimize retrieval accuracy by trying minimize the mean squared error \n",
    "between the model's output vectors and the vectors corresponding to the correct output items for each input cue. We'll use a large number of training examples that are distinct from our test data, so as to avoid explicitly fitting the model parameters to the test items. \n",
    "\n",
    "To make the example run a bit quicker, we'll download some pretrained model parameters by default. Set `do_training = True` to train the model yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = nengo_dl.Simulator(net, minibatch_size=20, seed=seed)\n",
    "\n",
    "# pick an optimizer and learning rate\n",
    "optimizer = tf.train.RMSPropOptimizer(1e-3)    \n",
    "\n",
    "do_training = False\n",
    "if do_training:\n",
    "    # create training data and data feeds\n",
    "    pointers, cues, targets, _ = get_data(n_items=5000, n_pairs=2, dims=dims, seed=seed+1)\n",
    "    train_inputs = {ptr_inp: pointers, cue_inp: cues}\n",
    "    train_outputs = {out: targets}\n",
    "\n",
    "    # train the model\n",
    "    sim.train(train_inputs, train_outputs, optimizer, n_epochs=100, objective='mse')\n",
    "    sim.save_params('./spa_retrieval_params')\n",
    "\n",
    "else:\n",
    "    # download pretrained parameters\n",
    "    urlretrieve(\n",
    "        \"https://drive.google.com/uc?export=download&id=0BxRAh6Eg1us4aGo3LVdkYm5xeFE\",\n",
    "        \"spa_retrieval_params.zip\")\n",
    "    with zipfile.ZipFile(\"spa_retrieval_params.zip\") as f:\n",
    "        f.extractall()\n",
    "        \n",
    "    # load parameters\n",
    "    sim.load_params('./spa_retrieval_params')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test improved retrieval accuracy\n",
    "\n",
    "We can now recompute the network outputs with our test data using the trained model. As these results illustrate, it is possible to boost retrieval accuracy from approximately 10% percent to 95% using a relatively small amount of training data. You can modify the dimensionality of the SPs and the number of bound pairs in each SP to determine how these variables influence the upper bound on retrieval accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.step(input_feeds=test_inputs)\n",
    "print('Retrieval accuracy: ', accuracy(sim, out, vocab, target_keys))\n",
    "\n",
    "# reset and run for 100 milliseconds to create plot\n",
    "sim.soft_reset()\n",
    "sim.run(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[out_filtered][0], output_vocab))\n",
    "plt.legend(output_vocab.keys, loc=4)\n",
    "plt.ylim([-1, 1])\n",
    "plt.xlabel(\"t [s]\")\n",
    "plt.ylabel(\"Similarity\");\n",
    "\n",
    "sim.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the plot above, the output is now most similar to `FILL_A0`, which is the correct output for the default input cue `ROLE_A0`. \n",
    "\n",
    "In the next tutorial, we'll look at optimizing the temporal trajectory of a similar model, in which a structured SP is built up over time by binding together sequentially presented input items. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
